#Regression all code 
import pandas as pd

# Load the dataset
data = pd.read_csv('/content/profit_prediction_regression.csv')
# Look at the first few rows of the dataset
print(data.head())


-----------------------------------------------------------------------

# Check for missing values
print(data.isnull().sum())

------------------------------------------------------------------------


# Check for missing values
print(data.isnull().sum())

# Check data types
print(data.dtypes)

# Look for outliers using a summary of statistics
print(data.describe())


------------------------------------------------------------------------------

from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import pandas as pd

# Load the dataset
uploaded_file_path = 'profit_prediction_regression.csv'
data = pd.read_csv(uploaded_file_path)

# Separate features and target variable
X = data.drop('Profit', axis=1)
y = data['Profit']

# Step 1: Label Encoding
label_encoder = LabelEncoder()
X_label_encoded = X.copy()
X_label_encoded['Area'] = label_encoder.fit_transform(X['Area'])  # Encode 'Area'

# Step 2: One-Hot Encoding
X_one_hot_encoded = pd.get_dummies(X, columns=['Area'], drop_first=True)  # One-hot encode 'Area'

# Step 3: Train-Test Split
X_train_label, X_test_label, y_train_label, y_test_label = train_test_split(X_label_encoded, y, test_size=0.2, random_state=42)
X_train_one_hot, X_test_one_hot, y_train_one_hot, y_test_one_hot = train_test_split(X_one_hot_encoded, y, test_size=0.2, random_state=42)

# Step 4: Train Regression Models
model_label = LinearRegression()
model_one_hot = LinearRegression()

# Train models
model_label.fit(X_train_label, y_train_label)
model_one_hot.fit(X_train_one_hot, y_train_one_hot)

# Predictions
y_pred_label = model_label.predict(X_test_label)
y_pred_one_hot = model_one_hot.predict(X_test_one_hot)

# Step 5: Evaluate Models
mse_label = mean_squared_error(y_test_label, y_pred_label)
r2_label = r2_score(y_test_label, y_pred_label)

mse_one_hot = mean_squared_error(y_test_one_hot, y_pred_one_hot)
r2_one_hot = r2_score(y_test_one_hot, y_pred_one_hot)

# Print Results
print("Label Encoding Results:")
print(f"Mean Squared Error: {mse_label}")
print(f"R² Score: {r2_label}")

print("\nOne-Hot Encoding Results:")
print(f"Mean Squared Error: {mse_one_hot}")
print(f"R² Score: {r2_one_hot}")


-----------------------------------------------------------------------------


from sklearn.linear_model import Lasso
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.model_selection import train_test_split
import numpy as np
import pandas as pd

# Load the dataset
uploaded_file_path = 'profit_prediction_regression.csv'
data = pd.read_csv(uploaded_file_path)

# Encode categorical variable (Area) using One-Hot Encoding
X = pd.get_dummies(data.drop('Profit', axis=1), columns=['Area'], drop_first=True)  # Features
y = data['Profit']  # Target

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train LASSO Regression
lasso = Lasso(alpha=0.1)  # Regularization strength (adjust alpha as needed)
lasso.fit(X_train, y_train)

# Identify selected features (non-zero coefficients)
selected_features = X.columns[(lasso.coef_ != 0)].tolist()

# Make predictions
y_pred = lasso.predict(X_test)

# Evaluate the model
r2 = r2_score(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
mae = mean_absolute_error(y_test, y_pred)

# Print Results
print("Selected Features by LASSO:", selected_features)
print(f"R² Score: {r2}")
print(f"Root Mean Squared Error (RMSE): {rmse}")
print(f"Mean Absolute Error (MAE): {mae}")

---------------------------------------------------------------------------

# Compute correlation matrix
correlation_matrix = X.corr()

# Find features with correlation > 0.85
correlated_features = correlation_matrix[correlation_matrix > 0.85]
print(correlated_features)

----------------------------------------------------------------------------

from sklearn.linear_model import Ridge
from sklearn.metrics import mean_squared_error, r2_score

# Train Ridge Regression
ridge = Ridge(alpha=0.1)
ridge.fit(X_train, y_train)

# Predictions and Evaluation
ridge_pred = ridge.predict(X_test)
print("Ridge MSE:", mean_squared_error(y_test, ridge_pred))
print("Ridge R²:", r2_score(y_test, ridge_pred))


----------------------------------------------------------------------------

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import Ridge, Lasso
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Load the dataset
uploaded_file_path = 'profit_prediction_regression.csv'
data = pd.read_csv(uploaded_file_path)

# Encode categorical variable (Area) using One-Hot Encoding
X = pd.get_dummies(data.drop('Profit', axis=1), columns=['Area'], drop_first=True)  # Features
y = data['Profit']  # Target

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define hyperparameter values (α)
alphas = [0.01, 0.1, 1, 10, 100]

# Initialize lists to store results
ridge_r2, lasso_r2 = [], []
ridge_rmse, lasso_rmse = [], []
#This line is split into two, to prevent a value error
ridge_mae = []
lasso_mae = []
ridge_coefficients, lasso_coefficients = [], []

# Train Ridge and Lasso models for different α values
for alpha in alphas:
    # Ridge Regression
    ridge = Ridge(alpha=alpha)
    ridge.fit(X_train, y_train)
    ridge_pred = ridge.predict(X_test)
    ridge_r2.append(r2_score(y_test, ridge_pred))
    ridge_rmse.append(np.sqrt(mean_squared_error(y_test, ridge_pred)))
    ridge_mae.append(mean_absolute_error(y_test, ridge_pred))
    ridge_coefficients.append(ridge.coef_)
    
    # Lasso Regression
    lasso = Lasso(alpha=alpha)
    lasso.fit(X_train, y_train)
    lasso_pred = lasso.predict(X_test)
    lasso_r2.append(r2_score(y_test, lasso_pred))
    lasso_rmse.append(np.sqrt(mean_squared_error(y_test, lasso_pred)))
    lasso_mae.append(mean_absolute_error(y_test, lasso_pred))
    lasso_coefficients.append(lasso.coef_)

# Step 4: Visualize Model Performance
plt.figure(figsize=(14, 6))

# R² Score Comparison
plt.subplot(1, 3, 1)
plt.plot(alphas, ridge_r2, label="Ridge R²", marker="o")
plt.plot(alphas, lasso_r2, label="Lasso R²", marker="o")
plt.xscale("log")
plt.xlabel("Alpha (log scale)")
plt.ylabel("R² Score")
plt.title("R² vs Alpha")
plt.legend()

# RMSE Comparison
plt.subplot(1, 3, 2)
plt.plot(alphas, ridge_rmse, label="Ridge RMSE", marker="o")
plt.plot(alphas, lasso_rmse, label="Lasso RMSE", marker="o")
plt.xscale("log")
plt.xlabel("Alpha (log scale)")
plt.ylabel("RMSE")
plt.title("RMSE vs Alpha")
plt.legend()

# MAE Comparison
plt.subplot(1, 3, 3)
plt.plot(alphas, ridge_mae, label="Ridge MAE", marker="o")
plt.plot(alphas, lasso_mae, label="Lasso MAE", marker="o")
plt.xscale("log")
plt.xlabel("Alpha (log scale)")
plt.ylabel("MAE")
plt.title("MAE vs Alpha")
plt.legend()

plt.tight_layout()
plt.show()

# Step 5: Visualize Coefficients
plt.figure(figsize=(12, 6))

# Plot Ridge Coefficients
plt.plot(alphas, ridge_coefficients, label="Ridge Coefficients", marker="o")
plt.xscale("log")
plt.xlabel("Alpha (log scale)")
plt.ylabel("Coefficient Value")
plt.title("Ridge Coefficients vs Alpha")
plt.show()

# Plot Lasso Coefficients
plt.figure(figsize=(12, 6))
plt.plot(alphas, lasso_coefficients, label="Lasso Coefficients", marker="o")
plt.xscale("log")
plt.xlabel("Alpha (log scale)")
plt.ylabel("Coefficient Value")
plt.title("Lasso Coefficients vs Alpha")
plt.show()


---------------------------------------------------------------------

from sklearn.model_selection import KFold
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

# Load the dataset
uploaded_file_path = 'profit_prediction_regression.csv'
data = pd.read_csv(uploaded_file_path)

# Encode categorical variable (Area) using One-Hot Encoding
X = pd.get_dummies(data.drop('Profit', axis=1), columns=['Area'], drop_first=True)  # Features
y = data['Profit']  # Target

# Step 1: Train-Test Split (No Cross-Validation)
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train the model without cross-validation
model = LinearRegression()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

# Evaluate without cross-validation
mse_no_cv = mean_squared_error(y_test, y_pred)
mae_no_cv = mean_absolute_error(y_test, y_pred)
r2_no_cv = r2_score(y_test, y_pred)
rmse_no_cv = np.sqrt(mse_no_cv)

# Step 2: k-Fold Cross-Validation
kf = KFold(n_splits=5, shuffle=True, random_state=42)  # 5 folds
mse_cv, mae_cv, r2_cv, rmse_cv = [], [], [], []

for train_index, test_index in kf.split(X):
    X_train_cv, X_test_cv = X.iloc[train_index], X.iloc[test_index]
    y_train_cv, y_test_cv = y.iloc[train_index], y.iloc[test_index]
    
    model.fit(X_train_cv, y_train_cv)
    y_pred_cv = model.predict(X_test_cv)
    
    mse_cv.append(mean_squared_error(y_test_cv, y_pred_cv))
    mae_cv.append(mean_absolute_error(y_test_cv, y_pred_cv))
    r2_cv.append(r2_score(y_test_cv, y_pred_cv))
    rmse_cv.append(np.sqrt(mean_squared_error(y_test_cv, y_pred_cv)))

# Average metrics across folds
mse_cv_mean = np.mean(mse_cv)
mae_cv_mean = np.mean(mae_cv)
r2_cv_mean = np.mean(r2_cv)
rmse_cv_mean = np.mean(rmse_cv)

# Print Results
print("Performance Without Cross-Validation:")
print(f"MSE: {mse_no_cv}, MAE: {mae_no_cv}, R²: {r2_no_cv}, RMSE: {rmse_no_cv}")

print("\nPerformance With Cross-Validation (Mean Across Folds):")
print(f"MSE: {mse_cv_mean}, MAE: {mae_cv_mean}, R²: {r2_cv_mean}, RMSE: {rmse_cv_mean}")

# Step 3: Visualization
folds = range(1, 6)
plt.figure(figsize=(14, 6))

# Plot MSE
plt.subplot(1, 2, 1)
plt.plot(folds, mse_cv, marker='o', label='MSE per fold', color='blue')
plt.axhline(y=mse_cv_mean, color='red', linestyle='--', label='Mean MSE')
plt.title('MSE Across Folds')
plt.xlabel('Fold')
plt.ylabel('MSE')
plt.legend()

# Plot R²
plt.subplot(1, 2, 2)
plt.plot(folds, r2_cv, marker='o', label='R² per fold', color='green')
plt.axhline(y=r2_cv_mean, color='red', linestyle='--', label='Mean R²')
plt.title('R² Across Folds')
plt.xlabel('Fold')
plt.ylabel('R² Score')
plt.legend()

plt.tight_layout()
plt.show()


-------------------------------------------------------------------------



from sklearn.preprocessing import MinMaxScaler, StandardScaler
import pandas as pd

# Load the dataset
uploaded_file_path = 'profit_prediction_regression.csv'
data = pd.read_csv(uploaded_file_path)

# Select numerical columns for scaling
numerical_features = ['Marketing Spend', 'Administration', 'Transport']

# Step 1: Min-Max Scaling (Normalization)
min_max_scaler = MinMaxScaler()
normalized_data = pd.DataFrame(
    min_max_scaler.fit_transform(data[numerical_features]),
    columns=numerical_features
)

# Step 2: Standardization (Z-score Scaling)
z_score_scaler = StandardScaler()
standardized_data = pd.DataFrame(
    z_score_scaler.fit_transform(data[numerical_features]),
    columns=numerical_features
)

# Combine original, normalized, and standardized data for comparison
comparison = pd.concat([data[numerical_features], normalized_data, standardized_data], axis=1)
comparison.columns = [
    "Original_Marketing_Spend", "Original_Administration", "Original_Transport",
    "Normalized_Marketing_Spend", "Normalized_Administration", "Normalized_Transport",
    "Standardized_Marketing_Spend", "Standardized_Administration", "Standardized_Transport"
]

# Display the first few rows of the comparison
print(comparison.head())













